<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <!-- springProfile用于指定当前激活的环境，如果spring.profile.active的值是哪个，就会激活对应节点下的配置 -->
    <springProfile name="default">
        <!-- configuration to be enabled when the "staging" profile is active -->
        <springProperty scope="context" name="module" source="spring.application.name" defaultValue="undefinded"/>
        <!-- 该节点会读取Environment中配置的值，在这里我们读取application.yml中的值 -->
        <springProperty scope="context" name="bootstrapServers" source="spring.kafka.bootstrap-servers"
                        defaultValue="172.20.10.2:9092"/>
        <springProperty scope="context" name="topicName" source="spring.kafka.topic.userTopic"
                        defaultValue="elk_kafka"/>


        <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
            <!-- encoders are assigned the type
                 ch.qos.logback.classic.encoder.PatternLayoutEncoder by default -->
            <encoder>
                <!--<pattern>%boldYellow(${module} | %d | %-5level| %logger{15}) - %msg %n</pattern>-->
<!--
                <pattern>%boldYellow([%date{yyyy-MM-dd HH:mm:ss.SSS}] | %X{logthreadId} |  %-5level %logger{80}) | %line | - %msg%n</pattern>
-->
                <pattern>%boldYellow(%date{yyyy-MM-dd HH:mm:ss.SSS} | %thread | %-5level | %logger{36}.%M\(%line\) | -) %msg%n</pattern>
            </encoder>
        </appender>


        <!-- kafka的appender配置 -->
        <appender name="kafka" class="com.github.danielwegener.logback.kafka.KafkaAppender">
            <!--<encoder>
                <pattern>${module} | %d | %-5level| %logger{15} - %msg</pattern>
            </encoder>-->


            <encoder
                    class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
                <providers>
                    <timestamp>
                        <timeZone>UTC</timeZone>
                    </timestamp>
                    <pattern>
                        <pattern>
                            {
                            "time":"%date{yyyy-MM-dd HH:mm:ss.SSS}",        <!--时间戳-->
                            "level": "%level",  <!--日志级别-->
                            "className": "%logger{80}", <!--类名-->
                            "method": "%M",            <!--方法名-->
                            "lineNumber": "%line", <!--行号-->
                            "thread": "%thread",    <!--线程名-->
                            "message": "%message"   <!--日志信息-->

                            }
                        </pattern>
                    </pattern>
                </providers>
            </encoder>


            <topic>elk_kafka</topic>
            <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"/>
            <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"/>
            <!-- bootstrap.servers is the only mandatory producerConfig -->
            <producerConfig>bootstrap.servers=${bootstrapServers}</producerConfig>

            <!-- 如果kafka不可用则输出到控制台 -->
            <appender-ref ref="STDOUT"/>

        </appender>
        <!-- 指定项目中的logger -->
        <!--<logger name="org.springframework.test" level="INFO" >
            <appender-ref ref="kafka" />
        </logger>-->
        <root level="info">
            <appender-ref ref="STDOUT" />
            <appender-ref ref="kafka" />
        </root>

    </springProfile>
</configuration>